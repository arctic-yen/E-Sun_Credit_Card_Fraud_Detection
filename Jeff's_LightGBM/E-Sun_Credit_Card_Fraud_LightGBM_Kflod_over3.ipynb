{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.56)\n",
    "import gc\n",
    "\n",
    "import os, sys, random, math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, GroupKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\tSuccessfully loaded train_identity!\n",
      "\tSuccessfully loaded test_identity!\n",
      "\tSuccessfully loaded train_identity!\n",
      "Data was successfully loaded!\n",
      "\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "train = pd.read_csv('C:\\\\Users\\\\洪廷奇\\\\Desktop\\\\E-Sun_Credit_Card_Fraud_EDA/train.csv', index_col='txkey')\n",
    "print('\\tSuccessfully loaded train_identity!')\n",
    "\n",
    "test = pd.read_csv('C:\\\\Users\\\\洪廷奇\\\\Desktop\\\\E-Sun_Credit_Card_Fraud_EDA/test.csv', index_col='txkey')\n",
    "print('\\tSuccessfully loaded test_identity!')\n",
    "\n",
    "fruad = pd.read_csv('C:\\\\Users\\\\洪廷奇\\\\Desktop\\\\E-Sun_Credit_Card_Fraud_EDA/fruad.csv', index_col='txkey')\n",
    "print('\\tSuccessfully loaded train_identity!')\n",
    "\n",
    "\n",
    "print('Data was successfully loaded!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['flbmk'] = train['flbmk'].fillna('Nan')\n",
    "train['flg_3dsmk'] = train['flg_3dsmk'].fillna('Nan')\n",
    "\n",
    "test['flbmk'] = test['flbmk'].fillna('Nan')\n",
    "test['flg_3dsmk'] = test['flg_3dsmk'].fillna('Nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_null_train = train.isnull().sum()\n",
    "check_null_train[check_null_train>0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_null_test = test.isnull().sum()\n",
    "check_null_test[check_null_test>0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(dataframe):\n",
    "    \n",
    "    dataframe['ecfg'] = dataframe['ecfg'].map({'Y':1, 'N':0})\n",
    "    dataframe['ovrlt'] = dataframe['ovrlt'].map({'Y':1, 'N':0})\n",
    "    dataframe['flbmk'] = dataframe['flbmk'].map({'Y':2, 'N':1, 'Nan':0})\n",
    "    dataframe['flg_3dsmk'] = dataframe['flg_3dsmk'].map({'Y':2, 'N':1, 'Nan':0})\n",
    "    dataframe['insfg'] = dataframe['insfg'].map({'Y':1, 'N':0})\n",
    "    dataframe['locdt_M'] = dataframe['locdt'].map({1:1,2:1,3:1,4:1,5:1,6:1,7:1,8:1,9:1,10:1,11:1,12:1,13:1,14:1,15:1,\n",
    "                                                   16:1,17:1,18:1,19:1,20:1,21:1,22:1,23:1,24:1,25:1,26:1,27:1,28:1,29:1,30:1,31:1,\n",
    "                                                   32:2,33:2,34:2,35:2,36:2,37:2,38:2,39:2,40:2,41:2,42:2,43:2,44:2,45:2,\n",
    "                                                   46:2,47:2,48:2,49:2,50:2,51:2,52:2,53:2,54:2,55:2,56:2,57:2,58:2,59:2,60:2,61:2,\n",
    "                                                   62:3,63:3,64:3,65:3,66:3,67:3,68:3,69:3,70:3,71:3,72:3,73:3,74:3,75:3,\n",
    "                                                   76:3,77:3,78:3,79:3,80:3,81:3,82:3,83:3,84:3,85:3,86:3,87:3,88:3,89:3,90:3,91:3,92:3,\n",
    "                                                   93:4,94:4,95:4,96:4,97:4,98:4,99:4,100:4,101:4,102:4,103:4,104:4,105:4,106:4,107:4,\n",
    "                                                   108:4,109:4,110:4,111:4,112:4,113:4,114:4,115:4,116:4,117:4,118:4,119:4,120:4})\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_split(train)\n",
    "test = data_split(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['txn_info'] = train['flg_3dsmk'].astype(str)+train['flbmk'].astype(str)+train['stscd'].astype(str)+train['ovrlt'].astype(str)\n",
    "test['txn_info'] = test['flg_3dsmk'].astype(str)+test['flbmk'].astype(str)+test['stscd'].astype(str)+test['ovrlt'].astype(str)\n",
    "fruad['txn_info'] = fruad['flg_3dsmk'].astype(str)+fruad['flbmk'].astype(str)+fruad['stscd'].astype(str)+fruad['ovrlt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskCountry = [104, 75]\n",
    "train['HighRiskCountry'] = train['stocn'].apply(lambda x: 1 if x in RiskCountry else 0)\n",
    "test['HighRiskCountry'] = test['stocn'].apply(lambda x: 1 if x in RiskCountry else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskCurrency = [60, 61]\n",
    "train['HighRiskCurrency'] = train['csmcu'].apply(lambda x: 1 if x in RiskCurrency else 0)\n",
    "test['HighRiskCurrency'] = test['csmcu'].apply(lambda x: 1 if x in RiskCurrency else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['HighRiskFlag'] = train['HighRiskCountry'].astype(str)+train['HighRiskCurrency'].astype(str)\n",
    "test['HighRiskFlag'] = test['HighRiskCountry'].astype(str)+test['HighRiskCurrency'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['conam_decimal'] = ((train['conam'] - train['conam'].astype(int)) * 1000).astype(int)\n",
    "test['conam_decimal'] = ((test['conam'] - test['conam'].astype(int)) * 1000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['HighRiskLowerAmount'] = 0\n",
    "test['HighRiskLowerAmount'] = 0\n",
    "\n",
    "train['HighRiskLowerAmount'] = train['conam'] < 201\n",
    "test['HighRiskLowerAmount'] = test['conam'] < 201\n",
    "\n",
    "train['HighRiskLowerAmount'] = train['HighRiskLowerAmount'].map({True:1, False:0})\n",
    "test['HighRiskLowerAmount'] = test['HighRiskLowerAmount'].map({True:1, False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['HighRiskHigherAmount'] = 0\n",
    "test['HighRiskHigherAmount'] = 0\n",
    "\n",
    "train['HighRiskHigherAmount'] = train['conam'] > 999\n",
    "test['HighRiskHigherAmount'] = test['conam'] > 999\n",
    "\n",
    "train['HighRiskHigherAmount'] = train['HighRiskHigherAmount'].map({True:1, False:0})\n",
    "test['HighRiskHigherAmount'] = test['HighRiskHigherAmount'].map({True:1, False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['loct_hour'] = train['loctm']//10000\n",
    "test['loct_hour'] = test['loctm']//10000\n",
    "fruad['loct_hour'] = fruad['loctm']//10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['locdt','txn_info']: #'locdt_M'\n",
    "    temp_df = pd.concat([train[[col]], test[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()\n",
    "            \n",
    "    train[col+'_total'] = train[col].map(fq_encode)\n",
    "    test[col+'_total']  = test[col].map(fq_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply aggregations no logic\n",
    "train['conam_to_mean_cano'] = train['conam'] / train.groupby(['cano'])['conam'].transform('mean')\n",
    "train['conam_to_mean_bacno'] = train['conam'] / train.groupby(['bacno'])['conam'].transform('mean')\n",
    "test['conam_to_mean_cano'] = test['conam'] / test.groupby(['cano'])['conam'].transform('mean')\n",
    "test['conam_to_mean_bacno'] = test['conam'] / test.groupby(['bacno'])['conam'].transform('mean')\n",
    "\n",
    "train['conam_to_std_cano'] = train['conam'] / train.groupby(['cano'])['conam'].transform('std')\n",
    "train['conam_to_std_bacno'] = train['conam'] / train.groupby(['bacno'])['conam'].transform('std')\n",
    "test['conam_to_std_cano'] = test['conam'] / test.groupby(['cano'])['conam'].transform('std')\n",
    "test['conam_to_std_bacno'] = test['conam'] / test.groupby(['bacno'])['conam'].transform('std')\n",
    "\n",
    "train['conam_to_mean_mchno'] = train['conam'] / train.groupby(['mchno'])['conam'].transform('mean')\n",
    "train['conam_to_mean_mcc'] = train['conam'] / train.groupby(['mcc'])['conam'].transform('mean')\n",
    "train['conam_to_mean_hcefg'] = train['conam'] / train.groupby(['hcefg'])['conam'].transform('mean')\n",
    "test['conam_to_mean_mchno'] = test['conam'] / test.groupby(['mchno'])['conam'].transform('mean')\n",
    "test['conam_to_mean_mcc'] = test['conam'] / test.groupby(['mcc'])['conam'].transform('mean')\n",
    "test['conam_to_mean_hcefg'] = test['conam'] / test.groupby(['hcefg'])['conam'].transform('mean')\n",
    "\n",
    "train['conam_to_std_mchno'] = train['conam'] / train.groupby(['mchno'])['conam'].transform('std')\n",
    "train['conam_to_std_mcc'] = train['conam'] / train.groupby(['mcc'])['conam'].transform('std')\n",
    "train['conam_to_std_hcefg'] = train['conam'] / train.groupby(['hcefg'])['conam'].transform('std')\n",
    "test['conam_to_std_mchno'] = test['conam'] / test.groupby(['mchno'])['conam'].transform('std')\n",
    "test['conam_to_std_mcc'] = test['conam'] / test.groupby(['mcc'])['conam'].transform('std')\n",
    "test['conam_to_std_hcefg'] = test['conam'] / test.groupby(['hcefg'])['conam'].transform('std')\n",
    "\n",
    "train['conam_to_mean_acqic'] = train['conam'] / train.groupby(['acqic'])['conam'].transform('mean')\n",
    "test['conam_to_mean_acqic'] = test['conam'] / test.groupby(['acqic'])['conam'].transform('mean')\n",
    "\n",
    "train['conam_to_std_acqic'] = train['conam'] / train.groupby(['acqic'])['conam'].transform('std')\n",
    "test['conam_to_std_acqic'] = test['conam'] / test.groupby(['acqic'])['conam'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check amount\n",
    "train['conam_check'] = np.where(train['conam'].isin(test['conam']), 1, 0)\n",
    "test['conam_check']  = np.where(test['conam'].isin(train['conam']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cano\n",
    "train['cano_check'] = np.where(train['cano'].isin(test['cano']), 1, 0)\n",
    "test['cano_check']  = np.where(test['cano'].isin(train['cano']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['fruad_check'] = train['cano'].astype(str)+'_'+train['acqic'].astype(str)+'_'+train['mchno'].astype(str)\n",
    "#test['fruad_check'] = test['cano'].astype(str)+'_'+test['acqic'].astype(str)+'_'+test['mchno'].astype(str)\n",
    "#fruad['fruad_check'] = fruad['cano'].astype(str)+'_'+fruad['acqic'].astype(str)+'_'+fruad['mchno'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['fruad_check'] = train['mchno'].astype(str)\n",
    "#test['fruad_check'] = train['mchno'].astype(str)\n",
    "#fruad['fruad_check'] = fruad['mchno'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['HighRiskCano'] = np.where(train['cano'].isin(fruad['cano']), 1, 0)\n",
    "test['HighRiskCano'] = np.where(test['cano'].isin(fruad['cano']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['uid'] = train['cano'].astype(str)+'_'+train['bacno'].astype(str)\n",
    "test['uid'] = test['cano'].astype(str)+'_'+test['bacno'].astype(str)\n",
    "\n",
    "train['uid2'] = train['uid'].astype(str)+'_'+train['acqic'].astype(str)\n",
    "test['uid2'] = test['uid'].astype(str)+'_'+test['acqic'].astype(str)\n",
    "\n",
    "train['uid3'] = train['uid2'].astype(str)+'_'+train['mchno'].astype(str)+'_'+train['mcc'].astype(str)\n",
    "test['uid3'] = test['uid2'].astype(str)+'_'+test['mchno'].astype(str)+'_'+test['mcc'].astype(str)\n",
    "\n",
    "train['uid4'] = train['uid'].astype(str)+'_'+train['stocn'].astype(str)+'_'+train['scity'].astype(str)+'_'+train['csmcu'].astype(str)\n",
    "test['uid4'] = test['uid'].astype(str)+'_'+test['stocn'].astype(str)+'_'+test['scity'].astype(str)+'_'+test['csmcu'].astype(str)\n",
    "\n",
    "\n",
    "#train['uid5'] = train['mchno'].astype(str)+'_'+train['scity'].astype(str)+'_'+train['mcc'].astype(str)\n",
    "#test['uid5'] = test['mchno'].astype(str)+'_'+test['scity'].astype(str)+'_'+test['mcc'].astype(str)\n",
    "\n",
    "#train['uid4'] = train['uid'].astype(str)+'_'+train['stocn'].astype(str)+'_'+train['csmcu'].astype(str)\n",
    "#test['uid4'] = test['uid'].astype(str)+'_'+test['stocn'].astype(str)+'_'+test['csmcu'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = ['locdt','txn_info'] #'locdt_M'\n",
    "i_cols = ['uid']\n",
    "for period in periods:\n",
    "    for col in i_cols:\n",
    "        new_column = col + '_' + period\n",
    "            \n",
    "        temp_df = pd.concat([train[[col,period]], test[[col,period]]])\n",
    "        temp_df[new_column] = temp_df[col].astype(str) + '_' + (temp_df[period]).astype(str)\n",
    "        fq_encode = temp_df[new_column].value_counts().to_dict()\n",
    "            \n",
    "        train[new_column] = (train[col].astype(str) + '_' + train[period].astype(str)).map(fq_encode)\n",
    "        test[new_column]  = (test[col].astype(str) + '_' + test[period].astype(str)).map(fq_encode)\n",
    "        \n",
    "        train[new_column] /= train[period+'_total']\n",
    "        test[new_column]  /= test[period+'_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_cols = ['uid','uid2','uid3','uid4']\n",
    "\n",
    "for col in uid_cols:\n",
    "    for agg_type in ['mean','std']:\n",
    "        new_col_name = col+'_conam_'+agg_type\n",
    "        temp_df = pd.concat([train[[col, 'conam']], test[[col,'conam']]])\n",
    "        temp_df = temp_df.groupby([col])['conam'].agg([agg_type]).reset_index().rename(\n",
    "                                                  columns={agg_type: new_col_name})\n",
    "        \n",
    "        temp_df.index = list(temp_df[col])\n",
    "        temp_df = temp_df[new_col_name].to_dict()   \n",
    "    \n",
    "        train[new_col_name] = train[col].map(temp_df)\n",
    "        test[new_col_name]  = test[col].map(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['cano', 'bacno', 'acqic', 'mchno', 'mcc']:\n",
    "    train[feature + '_count_full'] = train[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    test[feature + '_count_full'] = test[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features interaction\n",
    "for feature in ['cano__bacno', 'stocn__scity', 'csmcu__etymd', 'ecfg__contp', 'mchno__mcc',\n",
    "                'ecfg__etymd', 'acqic__hcefg', 'mchno__hcefg', 'insfg__iterm', 'stscd__etymd']:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    train[feature] = train[f1].astype(str) + '_' + train[f2].astype(str)\n",
    "    test[feature] = test[f1].astype(str) + '_' + test[f2].astype(str)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n",
    "    train[feature] = le.transform(list(train[feature].astype(str).values))\n",
    "    test[feature] = le.transform(list(test[feature].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['contp','etymd','hcefg']:\n",
    "    temp_dict = train.groupby([col])['fraud_ind'].agg(['mean']).reset_index().rename(\n",
    "                                                           columns={'mean': col+'_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "    train[col+'_target_mean'] = train[col].map(temp_dict)\n",
    "    test[col+'_target_mean']  = test[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency encodeing \n",
    "fq_cols = ['cano', 'bacno', 'mchno', 'mcc', 'acqic',\n",
    "           'stocn', 'scity', 'csmcu', 'txn_info',\n",
    "           'contp','etymd', 'hcefg', 'HighRiskFlag',\n",
    "           'uid', 'uid2', 'uid3']\n",
    "\n",
    "for col in fq_cols:\n",
    "    temp_df = pd.concat([train[[col]], test[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()   \n",
    "    train[col+'_fq_enc'] = train[col].map(fq_encode)\n",
    "    test[col+'_fq_enc']  = test[col].map(fq_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['HighRiskHigherAmount__etymd', 'HighRiskLowerAmount__etymd']:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    train[feature] = train[f1].astype(str) + '_' + train[f2].astype(str)\n",
    "    test[feature] = test[f1].astype(str) + '_' + test[f2].astype(str)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n",
    "    train[feature] = le.transform(list(train[feature].astype(str).values))\n",
    "    test[feature] = le.transform(list(test[feature].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['txn_time_info'] = train['locdt'].astype(str)+'_'+train['loct_hour'].astype(str)+'_'+train['cano'].astype(str)+'_'+train['bacno'].astype(str)\n",
    "#test['txn_time_info'] = test['locdt'].astype(str)+'_'+test['loct_hour'].astype(str)+'_'+test['cano'].astype(str)+'_'+test['bacno'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for feature in ['txn_time_info']:\n",
    "#    train[feature + '_count_full'] = train[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "#    test[feature + '_count_full'] = test[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 features are going to be dropped for being useless\n"
     ]
    }
   ],
   "source": [
    "# drop noise data\n",
    "cols_to_drop = ['loctm','uid','uid2','uid3','uid4',\n",
    "                'txn_info','txn_info_total','HighRiskCountry','HighRiskCurrency']\n",
    "\n",
    "print('{} features are going to be dropped for being useless'.format(len(cols_to_drop)))\n",
    "\n",
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = lbl.transform(list(train[col].astype(str).values))\n",
    "        test[col] = lbl.transform(list(test[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of y_train data : (1521787,)\n",
      "Size of X_train data : (1521787, 87)\n",
      "Size of test data : (421665, 87)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train.sort_values('locdt')['fraud_ind']\n",
    "X = train.sort_values('locdt').drop(['fraud_ind','locdt'], axis=1)\n",
    "\n",
    "X_test = test.drop('locdt', axis=1)\n",
    "\n",
    "print (\"Size of y_train data : {}\" .format(y.shape))\n",
    "print (\"Size of X_train data : {}\" .format(X.shape))\n",
    "print (\"Size of test data : {}\" .format(X_test.shape))\n",
    "\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untuning params\n",
    "params = {'objective': 'binary',\n",
    "          'boosting_type': 'gbdt',\n",
    "          'metric': 'auc',\n",
    "          'learning_rate': 0.007,\n",
    "          'num_leaves': 2**8,\n",
    "          'max_depth': -1,\n",
    "          'tree_learner':'serial',\n",
    "          'colsample_bytree': 0.5,\n",
    "          'subsample_freq':1,\n",
    "          'subsample':0.7,\n",
    "          'n_estimators':10000,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'max_bin':255,\n",
    "          'verbosity': -1,\n",
    "          'seed': SEED,\n",
    "          'early_stopping_rounds':100,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's auc: 0.999713\tvalid_1's auc: 0.999403\n",
      "Fold 1 | AUC: 0.9994033800013256\n",
      "F1 score at threshold 0.1 is 0.8535050928699819\n",
      "F1 score at threshold 0.11 is 0.8405078971817901\n",
      "F1 score at threshold 0.12 is 0.8208427146992602\n",
      "F1 score at threshold 0.13 is 0.7863476660532039\n",
      "F1 score at threshold 0.14 is 0.735247489871411\n",
      "F1 score at threshold 0.15 is 0.6896297660710997\n",
      "F1 score at threshold 0.16 is 0.652455272173582\n",
      "F1 score at threshold 0.17 is 0.600475624256837\n",
      "F1 score at threshold 0.18 is 0.5437254496588794\n",
      "F1 score at threshold 0.19 is 0.4711517526671021\n",
      "F1 score at threshold 0.2 is 0.24573721163490472\n",
      "F1 score at threshold 0.21 is 0.018140589569160998\n",
      "F1 score at threshold 0.22 is 0.0005719187875321705\n",
      "F1 score at threshold 0.23 is 0.0\n",
      "F1 score at threshold 0.24 is 0.0\n",
      "F1 score at threshold 0.25 is 0.0\n",
      "F1 score at threshold 0.26 is 0.0\n",
      "F1 score at threshold 0.27 is 0.0\n",
      "F1 score at threshold 0.28 is 0.0\n",
      "F1 score at threshold 0.29 is 0.0\n",
      "F1 score at threshold 0.3 is 0.0\n",
      "F1 score at threshold 0.31 is 0.0\n",
      "F1 score at threshold 0.32 is 0.0\n",
      "F1 score at threshold 0.33 is 0.0\n",
      "F1 score at threshold 0.34 is 0.0\n",
      "F1 score at threshold 0.35 is 0.0\n",
      "F1 score at threshold 0.36 is 0.0\n",
      "F1 score at threshold 0.37 is 0.0\n",
      "F1 score at threshold 0.38 is 0.0\n",
      "F1 score at threshold 0.39 is 0.0\n",
      "F1 score at threshold 0.4 is 0.0\n",
      "F1 score at threshold 0.41 is 0.0\n",
      "F1 score at threshold 0.42 is 0.0\n",
      "F1 score at threshold 0.43 is 0.0\n",
      "F1 score at threshold 0.44 is 0.0\n",
      "F1 score at threshold 0.45 is 0.0\n",
      "F1 score at threshold 0.46 is 0.0\n",
      "F1 score at threshold 0.47 is 0.0\n",
      "F1 score at threshold 0.48 is 0.0\n",
      "F1 score at threshold 0.49 is 0.0\n",
      "F1 score at threshold 0.5 is 0.0\n",
      "Best threshold:  0.1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.999832\tvalid_1's auc: 0.999363\n",
      "[400]\ttraining's auc: 0.99989\tvalid_1's auc: 0.999427\n",
      "[600]\ttraining's auc: 0.999935\tvalid_1's auc: 0.999466\n",
      "[800]\ttraining's auc: 0.999963\tvalid_1's auc: 0.999487\n",
      "[1000]\ttraining's auc: 0.999982\tvalid_1's auc: 0.999497\n",
      "[1200]\ttraining's auc: 0.999991\tvalid_1's auc: 0.999502\n",
      "[1400]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999507\n",
      "[1600]\ttraining's auc: 0.999996\tvalid_1's auc: 0.999511\n",
      "[1800]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999513\n",
      "Early stopping, best iteration is:\n",
      "[1879]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999514\n",
      "Fold 2 | AUC: 0.9995136641596033\n",
      "F1 score at threshold 0.1 is 0.8935152374202693\n",
      "F1 score at threshold 0.11 is 0.8951483916829572\n",
      "F1 score at threshold 0.12 is 0.8953602279811204\n",
      "F1 score at threshold 0.13 is 0.8964901312851656\n",
      "F1 score at threshold 0.14 is 0.8980360505784234\n",
      "F1 score at threshold 0.15 is 0.9007468730315845\n",
      "F1 score at threshold 0.16 is 0.9009561609236875\n",
      "F1 score at threshold 0.17 is 0.9010492040520984\n",
      "F1 score at threshold 0.18 is 0.9008076957981668\n",
      "F1 score at threshold 0.19 is 0.9017572612218884\n",
      "F1 score at threshold 0.2 is 0.8993854902320462\n",
      "F1 score at threshold 0.21 is 0.9003126724296487\n",
      "F1 score at threshold 0.22 is 0.9020656584286242\n",
      "F1 score at threshold 0.23 is 0.903040946483039\n",
      "F1 score at threshold 0.24 is 0.9045897079276773\n",
      "F1 score at threshold 0.25 is 0.9052220776807286\n",
      "F1 score at threshold 0.26 is 0.9056884833814356\n",
      "F1 score at threshold 0.27 is 0.9058680847093944\n",
      "F1 score at threshold 0.28 is 0.905688622754491\n",
      "F1 score at threshold 0.29 is 0.9065639966194009\n",
      "F1 score at threshold 0.3 is 0.9070030120481927\n",
      "F1 score at threshold 0.31 is 0.9073235183087958\n",
      "F1 score at threshold 0.32 is 0.9079905437352245\n",
      "F1 score at threshold 0.33 is 0.9071773964160424\n",
      "F1 score at threshold 0.34 is 0.9068618133434708\n",
      "F1 score at threshold 0.35 is 0.9066666666666666\n",
      "F1 score at threshold 0.36 is 0.9062112393855548\n",
      "F1 score at threshold 0.37 is 0.905631513529018\n",
      "F1 score at threshold 0.38 is 0.9051542441080668\n",
      "F1 score at threshold 0.39 is 0.9051277126944497\n",
      "F1 score at threshold 0.4 is 0.90491298913566\n",
      "F1 score at threshold 0.41 is 0.905271273007613\n",
      "F1 score at threshold 0.42 is 0.9047894940131326\n",
      "F1 score at threshold 0.43 is 0.9048171793383633\n",
      "F1 score at threshold 0.44 is 0.9044067796610169\n",
      "F1 score at threshold 0.45 is 0.9041707080504365\n",
      "F1 score at threshold 0.46 is 0.9044289044289044\n",
      "F1 score at threshold 0.47 is 0.9043867328080926\n",
      "F1 score at threshold 0.48 is 0.9032761310452418\n",
      "F1 score at threshold 0.49 is 0.9033203125\n",
      "F1 score at threshold 0.5 is 0.903225806451613\n",
      "Best threshold:  0.32\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.999837\tvalid_1's auc: 0.999242\n",
      "[400]\ttraining's auc: 0.999894\tvalid_1's auc: 0.999317\n",
      "[600]\ttraining's auc: 0.999938\tvalid_1's auc: 0.999354\n",
      "[800]\ttraining's auc: 0.999967\tvalid_1's auc: 0.999377\n",
      "[1000]\ttraining's auc: 0.999983\tvalid_1's auc: 0.999387\n",
      "[1200]\ttraining's auc: 0.999991\tvalid_1's auc: 0.999389\n",
      "[1400]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999392\n",
      "[1600]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999395\n",
      "[1800]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999398\n",
      "Early stopping, best iteration is:\n",
      "[1877]\ttraining's auc: 0.999998\tvalid_1's auc: 0.9994\n",
      "Fold 3 | AUC: 0.9994007513434755\n",
      "F1 score at threshold 0.1 is 0.8871221387384238\n",
      "F1 score at threshold 0.11 is 0.8894736842105263\n",
      "F1 score at threshold 0.12 is 0.8902600264433672\n",
      "F1 score at threshold 0.13 is 0.8913486230408217\n",
      "F1 score at threshold 0.14 is 0.8926503340757238\n",
      "F1 score at threshold 0.15 is 0.89431330472103\n",
      "F1 score at threshold 0.16 is 0.8948927385333454\n",
      "F1 score at threshold 0.17 is 0.8933177022274326\n",
      "F1 score at threshold 0.18 is 0.8943986969505021\n",
      "F1 score at threshold 0.19 is 0.8957823129251701\n",
      "F1 score at threshold 0.2 is 0.8974242286338401\n",
      "F1 score at threshold 0.21 is 0.8977729098211026\n",
      "F1 score at threshold 0.22 is 0.8979778570775002\n",
      "F1 score at threshold 0.23 is 0.8981651376146789\n",
      "F1 score at threshold 0.24 is 0.8982443239268315\n",
      "F1 score at threshold 0.25 is 0.8981208548268239\n",
      "F1 score at threshold 0.26 is 0.8980985785490123\n",
      "F1 score at threshold 0.27 is 0.8978115727002969\n",
      "F1 score at threshold 0.28 is 0.8976480431347028\n",
      "F1 score at threshold 0.29 is 0.898407672967688\n",
      "F1 score at threshold 0.3 is 0.8986102042719895\n",
      "F1 score at threshold 0.31 is 0.8974095202468905\n",
      "F1 score at threshold 0.32 is 0.8956595106402926\n",
      "F1 score at threshold 0.33 is 0.8959429000751314\n",
      "F1 score at threshold 0.34 is 0.894855850763143\n",
      "F1 score at threshold 0.35 is 0.8950745423664843\n",
      "F1 score at threshold 0.36 is 0.8953785086475757\n",
      "F1 score at threshold 0.37 is 0.8954093705631804\n",
      "F1 score at threshold 0.38 is 0.8950810349729884\n",
      "F1 score at threshold 0.39 is 0.8938918970266931\n",
      "F1 score at threshold 0.4 is 0.893455098934551\n",
      "F1 score at threshold 0.41 is 0.8931872320152454\n",
      "F1 score at threshold 0.42 is 0.8931742243436753\n",
      "F1 score at threshold 0.43 is 0.8933728602849766\n",
      "F1 score at threshold 0.44 is 0.8936822931646055\n",
      "F1 score at threshold 0.45 is 0.8938010571840461\n",
      "F1 score at threshold 0.46 is 0.8919336163643381\n",
      "F1 score at threshold 0.47 is 0.8871859540207586\n",
      "F1 score at threshold 0.48 is 0.8869024485036923\n",
      "F1 score at threshold 0.49 is 0.8857504626473166\n",
      "F1 score at threshold 0.5 is 0.8844427093499903\n",
      "Best threshold:  0.3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.999831\tvalid_1's auc: 0.999366\n",
      "[400]\ttraining's auc: 0.999887\tvalid_1's auc: 0.999443\n",
      "[600]\ttraining's auc: 0.999932\tvalid_1's auc: 0.999507\n",
      "[800]\ttraining's auc: 0.999962\tvalid_1's auc: 0.999555\n",
      "[1000]\ttraining's auc: 0.999981\tvalid_1's auc: 0.999576\n",
      "[1200]\ttraining's auc: 0.99999\tvalid_1's auc: 0.999586\n",
      "[1400]\ttraining's auc: 0.999994\tvalid_1's auc: 0.999591\n",
      "[1600]\ttraining's auc: 0.999996\tvalid_1's auc: 0.999595\n",
      "[1800]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999598\n",
      "[2000]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999599\n",
      "Early stopping, best iteration is:\n",
      "[1942]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999599\n",
      "Fold 4 | AUC: 0.9995991831113825\n",
      "F1 score at threshold 0.1 is 0.8795416069800756\n",
      "F1 score at threshold 0.11 is 0.881484385208415\n",
      "F1 score at threshold 0.12 is 0.8826844933805217\n",
      "F1 score at threshold 0.13 is 0.8835309617918313\n",
      "F1 score at threshold 0.14 is 0.8856499271233603\n",
      "F1 score at threshold 0.15 is 0.8873220699747241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.16 is 0.8898701993844507\n",
      "F1 score at threshold 0.17 is 0.892530897367007\n",
      "F1 score at threshold 0.18 is 0.8932955618508026\n",
      "F1 score at threshold 0.19 is 0.8935135135135135\n",
      "F1 score at threshold 0.2 is 0.8932196508323182\n",
      "F1 score at threshold 0.21 is 0.8932302265635599\n",
      "F1 score at threshold 0.22 is 0.8928474299700844\n",
      "F1 score at threshold 0.23 is 0.8939765603706732\n",
      "F1 score at threshold 0.24 is 0.8944065484311051\n",
      "F1 score at threshold 0.25 is 0.8964290600629361\n",
      "F1 score at threshold 0.26 is 0.8971475589687329\n",
      "F1 score at threshold 0.27 is 0.8978694158075602\n",
      "F1 score at threshold 0.28 is 0.8986905582356994\n",
      "F1 score at threshold 0.29 is 0.8996405861210949\n",
      "F1 score at threshold 0.3 is 0.9000138677021218\n",
      "F1 score at threshold 0.31 is 0.90090340514246\n",
      "F1 score at threshold 0.32 is 0.9027042096459438\n",
      "F1 score at threshold 0.33 is 0.9022346368715084\n",
      "F1 score at threshold 0.34 is 0.9030362389813907\n",
      "F1 score at threshold 0.35 is 0.9040673211781206\n",
      "F1 score at threshold 0.36 is 0.9037786205927799\n",
      "F1 score at threshold 0.37 is 0.9036891016615038\n",
      "F1 score at threshold 0.38 is 0.9031893875246966\n",
      "F1 score at threshold 0.39 is 0.9044657998869416\n",
      "F1 score at threshold 0.4 is 0.905585483413666\n",
      "F1 score at threshold 0.41 is 0.9054782855520863\n",
      "F1 score at threshold 0.42 is 0.9059124502558271\n",
      "F1 score at threshold 0.43 is 0.905595899188381\n",
      "F1 score at threshold 0.44 is 0.9045512911970324\n",
      "F1 score at threshold 0.45 is 0.903659233847913\n",
      "F1 score at threshold 0.46 is 0.9029765311963366\n",
      "F1 score at threshold 0.47 is 0.9026523297491039\n",
      "F1 score at threshold 0.48 is 0.9015380192611757\n",
      "F1 score at threshold 0.49 is 0.9007215007215008\n",
      "F1 score at threshold 0.5 is 0.8994219653179191\n",
      "Best threshold:  0.42\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.999806\tvalid_1's auc: 0.999597\n",
      "[400]\ttraining's auc: 0.99987\tvalid_1's auc: 0.999638\n",
      "[600]\ttraining's auc: 0.99992\tvalid_1's auc: 0.999661\n",
      "[800]\ttraining's auc: 0.999954\tvalid_1's auc: 0.999679\n",
      "[1000]\ttraining's auc: 0.999976\tvalid_1's auc: 0.999687\n",
      "[1200]\ttraining's auc: 0.999987\tvalid_1's auc: 0.999692\n",
      "[1400]\ttraining's auc: 0.999993\tvalid_1's auc: 0.999694\n",
      "[1600]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999696\n",
      "[1800]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999697\n",
      "[2000]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999698\n",
      "Early stopping, best iteration is:\n",
      "[1972]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999699\n",
      "Fold 5 | AUC: 0.9996982735671873\n",
      "F1 score at threshold 0.1 is 0.889069351957122\n",
      "F1 score at threshold 0.11 is 0.8921168598008814\n",
      "F1 score at threshold 0.12 is 0.8930735221876535\n",
      "F1 score at threshold 0.13 is 0.8943997372310724\n",
      "F1 score at threshold 0.14 is 0.8965062623599209\n",
      "F1 score at threshold 0.15 is 0.8974528613959643\n",
      "F1 score at threshold 0.16 is 0.8978441127694858\n",
      "F1 score at threshold 0.17 is 0.8992015968063871\n",
      "F1 score at threshold 0.18 is 0.9002172822998497\n",
      "F1 score at threshold 0.19 is 0.9015405224380442\n",
      "F1 score at threshold 0.2 is 0.9010101010101009\n",
      "F1 score at threshold 0.21 is 0.9030405405405406\n",
      "F1 score at threshold 0.22 is 0.9040027137042063\n",
      "F1 score at threshold 0.23 is 0.9048510638297872\n",
      "F1 score at threshold 0.24 is 0.9066393582522615\n",
      "F1 score at threshold 0.25 is 0.9066666666666667\n",
      "F1 score at threshold 0.26 is 0.9069089662266415\n",
      "F1 score at threshold 0.27 is 0.9059005676931017\n",
      "F1 score at threshold 0.28 is 0.9054846498792687\n",
      "F1 score at threshold 0.29 is 0.9059474412171509\n",
      "F1 score at threshold 0.3 is 0.9064124783362218\n",
      "F1 score at threshold 0.31 is 0.907732406602954\n",
      "F1 score at threshold 0.32 is 0.9108669108669109\n",
      "F1 score at threshold 0.33 is 0.9114455722786139\n",
      "F1 score at threshold 0.34 is 0.9124036440084093\n",
      "F1 score at threshold 0.35 is 0.9114190492895983\n",
      "F1 score at threshold 0.36 is 0.9120647203658108\n",
      "F1 score at threshold 0.37 is 0.9133886046921855\n",
      "F1 score at threshold 0.38 is 0.9133663366336634\n",
      "F1 score at threshold 0.39 is 0.9149539333805812\n",
      "F1 score at threshold 0.4 is 0.9150675195451314\n",
      "F1 score at threshold 0.41 is 0.9138483446066217\n",
      "F1 score at threshold 0.42 is 0.9131752540559813\n",
      "F1 score at threshold 0.43 is 0.9114331723027375\n",
      "F1 score at threshold 0.44 is 0.9092539454806312\n",
      "F1 score at threshold 0.45 is 0.9087971274685818\n",
      "F1 score at threshold 0.46 is 0.9084038150080979\n",
      "F1 score at threshold 0.47 is 0.9084684684684685\n",
      "F1 score at threshold 0.48 is 0.9079089924160347\n",
      "F1 score at threshold 0.49 is 0.9067873303167421\n",
      "F1 score at threshold 0.5 is 0.9060573086688429\n",
      "Best threshold:  0.4\n",
      "\n",
      "Mean AUC = 0.9995230504365948\n",
      "Out of folds AUC = 0.9983193558346406\n",
      "\n",
      "Mean F1 Score = 0.7186295579576731\n",
      "Mean Recall score = 0.7025824174812545\n",
      "Mean Precision score = 0.7357431951609626\n",
      "Wall time: 4h 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NFOLDS = 5\n",
    "#folds = KFold(n_splits=NFOLDS, random_state=47 ,shuffle=True)\n",
    "folds = KFold(n_splits=NFOLDS)\n",
    "columns = X.columns\n",
    "splits = folds.split(X, y)\n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X.shape[0])\n",
    "auc_score = 0\n",
    "best_threshold = 0\n",
    "F1_score = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "cms= []\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = columns\n",
    "  \n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=200)\n",
    "    \n",
    "    feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n",
    "    \n",
    "    y_pred_valid = clf.predict(X_valid)\n",
    "    y_oof[valid_index] = y_pred_valid\n",
    "    print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")\n",
    "    \n",
    "    auc_score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS\n",
    "     \n",
    "    F1_score.append(f1_score(y_valid.values, y_pred_valid.round())) \n",
    "    recalls.append(recall_score(y_valid.values, y_pred_valid.round()))\n",
    "    precisions.append(precision_score(y_valid.values , y_pred_valid.round()))\n",
    "    cms.append(confusion_matrix(y_valid.values, y_pred_valid.round()))\n",
    "    \n",
    "    # Optimize f1 score\n",
    "    thresholds = []\n",
    "    for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "        thresh = np.round(thresh, 2)\n",
    "        res = f1_score(y_valid.values, (y_pred_valid > thresh).astype(int))\n",
    "        thresholds.append([thresh, res])\n",
    "        print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "        \n",
    "    thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "    best_thresh = thresholds[0][0]\n",
    "    print(\"Best threshold: \", best_thresh)\n",
    "    \n",
    "    y_preds += (clf.predict(X_test)>best_thresh).astype(int) / NFOLDS\n",
    "    \n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "    gc.collect()\n",
    "    \n",
    "print(f\"\\nMean AUC = {auc_score}\")\n",
    "print(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")\n",
    "print(f\"\\nMean F1 Score = {np.mean(F1_score)}\")\n",
    "print(f\"Mean Recall score = {np.mean(recalls)}\")\n",
    "print(f\"Mean Precision score = {np.mean(precisions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-ae796fb4289f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-ae796fb4289f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Mean AUC = 0.9880941086500521\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Mean AUC = 0.9880941086500521\n",
    "Out of folds AUC = 0.9886164328277743\n",
    "\n",
    "Mean F1 Score = 0.6491700088804422\n",
    "Best Threshold = 0.24400000000000005\n",
    "-------------------------------------------\n",
    "Mean AUC = 0.9863439641737028\n",
    "Out of folds AUC = 0.9854926269428487\n",
    "\n",
    "Mean F1 Score = 0.6393889254040238\n",
    "Wall time: 45min 57s\n",
    "-------------------------------------------\n",
    "Mean AUC = 0.9872535738726497\n",
    "Out of folds AUC = 0.9877709384782674\n",
    "\n",
    "Mean F1 Score = 0.6492521199805226"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSuccessfully loaded sample_submission!\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('C:\\\\Users\\\\洪廷奇\\\\Desktop\\\\E-Sun_Credit_Card_Fraud_EDA/submission_test.csv')\n",
    "print('\\tSuccessfully loaded sample_submission!')\n",
    "\n",
    "sub['fraud_ind'] = (y_preds > 0.5).astype(int)\n",
    "sub.to_csv(\"E-Sun_Credit_Card_Fraud_Detection_submission138.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances['average'] = feature_importances[[f'fold_{fold_n + 1}' for fold_n in range(folds.n_splits)]].mean(axis=1)\n",
    "feature_importances.to_csv('E-Sun_Credit_Card_Fraud_Detection_feature_importances_Kflod108.csv')\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "sns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(50), x='average', y='feature');\n",
    "plt.title('50 TOP features importance over {} folds average'.format(folds.n_splits));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/NFOLDS)*(NFOLDS/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
